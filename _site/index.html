<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Charlie Tran">

<title>Predicting Term Deposit Subscriptions: A Supervised Learning Approach – ml-term-deposit-subs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>

<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">ml-term-deposit-subs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#main-question" id="toc-main-question" class="nav-link" data-scroll-target="#main-question">Main Question</a></li>
  </ul></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a>
  <ul class="collapse">
  <li><a href="#k-nearest-neighbors-knn" id="toc-k-nearest-neighbors-knn" class="nav-link" data-scroll-target="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a></li>
  <li><a href="#support-vector-machine-svm" id="toc-support-vector-machine-svm" class="nav-link" data-scroll-target="#support-vector-machine-svm">Support Vector Machine (SVM)</a></li>
  </ul></li>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link" data-scroll-target="#data-analysis">Data Analysis</a>
  <ul class="collapse">
  <li><a href="#feature-selection-and-data-preprocessing-with-frequency-encoding" id="toc-feature-selection-and-data-preprocessing-with-frequency-encoding" class="nav-link" data-scroll-target="#feature-selection-and-data-preprocessing-with-frequency-encoding">Feature Selection and Data Preprocessing with Frequency Encoding</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#model-evaluation" id="toc-model-evaluation" class="nav-link" data-scroll-target="#model-evaluation">Model Evaluation</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#challenges-and-limitations" id="toc-challenges-and-limitations" class="nav-link" data-scroll-target="#challenges-and-limitations">Challenges and Limitations</a></li>
  <li><a href="#future-improvements" id="toc-future-improvements" class="nav-link" data-scroll-target="#future-improvements">Future Improvements</a></li>
  <li><a href="#final-conclusion" id="toc-final-conclusion" class="nav-link" data-scroll-target="#final-conclusion">Final Conclusion</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predicting Term Deposit Subscriptions: A Supervised Learning Approach</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Charlie Tran </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In today’s competitive financial industry, effective marketing strategies are critical for retaining customers and driving growth. One of the most pressing challenges faced by banks is optimizing outreach efforts to target clients who are most likely to respond positively to specific campaigns. Inefficient marketing not only wastes resources but can also lead to customer fatigue. A 2022 report by McKinsey &amp; Company highlights that excessive, untargeted outreach reduces customer trust and engagement over time (McKinsey &amp; Company, 2022). This issue is particularly pronounced in sectors such as banking, where customers are inundated with financial offers and promotions. To address this, data-driven marketing strategies have become essential for maximizing campaign effectiveness while maintaining customer satisfaction.</p>
<p>The Bank Marketing dataset, provided by the UCI Machine Learning Repository, reflects these real-world challenges by recording detailed information about clients of a Portuguese banking institution. This dataset includes attributes such as client demographics, financial status, and previous interactions with marketing campaigns, as well as the outcome of whether they subscribed to a term deposit. The importance of this problem lies in identifying the right clients to target, which can help banks reduce costs, improve conversion rates, and ultimately enhance their competitive edge in the industry.</p>
<p>A 2022 Deloitte study on financial services noted that successful customer retention strategies, including targeted marketing, can improve long-term profitability by up to 25% (Deloitte, 2022). Subscription-based financial products such as term deposits are a cornerstone of customer retention strategies, and predictive modeling can offer banks actionable insights to achieve this goal.</p>
<p>In this project, I aim to use supervised machine learning techniques to predict whether a client will subscribe to a term deposit. Specifically, I will employ two distinct supervised learning algorithms—K-Nearest Neighbors (KNN) and Support Vector Machine (SVM)—to build predictive models and evaluate their performance. Both methods offer unique strengths in capturing patterns within labeled data, enabling robust predictions. Using metrics such as accuracy, precision, recall, and F1-score, Iwill measure and compare the models’ effectiveness, with a particular focus on addressing class imbalance in the data. The findings of this project are expected to not only improve marketing efficiency for financial institutions but also provide a deeper understanding of how client characteristics influence subscription behavior.</p>
<section id="main-question" class="level2">
<h2 class="anchored" data-anchor-id="main-question">Main Question</h2>
<p>Which model, KNN or SVM, best predicts whether a a client will subscribe to a term deposit or not?</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="methodology" class="level1">
<h1>Methodology</h1>
<section id="k-nearest-neighbors-knn" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</h2>
<p>KNN is a simple, non-parametric algorithm that classifies an observation based on the majority class of its “k” nearest neighbors in the feature space. It assumes that similar observations are likely to belong to the same class. The distance between data points is typically measured using the Euclidean distance formula:</p>
<p><span class="math display">\[
d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
\]</span></p>
<section id="prediction-formula" class="level5">
<h5 class="anchored" data-anchor-id="prediction-formula">Prediction Formula:</h5>
<p>For a new observation <span class="math inline">\(x_{new}\)</span>:</p>
<ul>
<li>Compute the distance between <span class="math inline">\(x_{new}\)</span> and all observations in the training set.</li>
<li>Identify the <span class="math inline">\(k\)</span> nearest neighbors based on these distances.</li>
<li>Assign <span class="math inline">\(x_{new}\)</span> to the class most frequent among these <span class="math inline">\(k\)</span> neighbors.</li>
</ul>
</section>
<section id="advantages" class="level5">
<h5 class="anchored" data-anchor-id="advantages">Advantages:</h5>
<ul>
<li>Easy to implement and interpret.</li>
<li>Effective for smaller datasets with well-separated classes.</li>
</ul>
</section>
<section id="disadvantages" class="level5">
<h5 class="anchored" data-anchor-id="disadvantages">Disadvantages:</h5>
<ul>
<li>Computationally expensive for large datasets, as it requires calculating distances for all observations.</li>
<li>Sensitive to irrelevant features and class imbalance.</li>
</ul>
</section>
<section id="application-in-project" class="level5">
<h5 class="anchored" data-anchor-id="application-in-project">Application in Project:</h5>
<p>I will experiment with different values of <span class="math inline">\(k\)</span> to find the optimal number of neighbors. Cross-validation will be used to evaluate the model’s performance, and I will preprocess the data (e.g., normalization) to ensure that features are on a comparable scale.</p>
</section>
</section>
<section id="support-vector-machine-svm" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-machine-svm">Support Vector Machine (SVM)</h2>
<p>SVM is a robust classification algorithm that works by finding a hyperplane that best separates the data points into two classes. It maximizes the margin between the closest points (support vectors) of each class to the hyperplane. The decision boundary is represented as:</p>
<p><span class="math display">\[
f(x)=w^Tx+b
\]</span></p>
<p>where <span class="math inline">\(w\)</span> is the weight vector, x represents the input features, and b is the bias term. SVM optimizes the following objective:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; \text{minimize}_{w, b} \quad \frac{1}{2} \| \mathbf{w} \|^2 \\
    &amp; \text{subject to } \quad y_i (\mathbf{w}^\top \mathbf{x}_i - b) \geq 1 \quad \forall i \in \{1, \ldots, n\}
\end{aligned}
\]</span></p>
<section id="kernel-trick" class="level5">
<h5 class="anchored" data-anchor-id="kernel-trick">Kernel Trick:</h5>
<p>For non-linear separable data, SVM uses kernel functions (e.g., linear, polynomial, radial basis function) to map the data into a higher-dimensional space, making it linearly separable.</p>
</section>
<section id="advantages-1" class="level5">
<h5 class="anchored" data-anchor-id="advantages-1">Advantages:</h5>
<ul>
<li>Effective in high-dimensional spaces.</li>
<li>Works well with non-linear boundaries using appropriate kernels.</li>
<li>Robust to overfitting in many cases due to regularization.</li>
</ul>
</section>
<section id="disadvantages-1" class="level5">
<h5 class="anchored" data-anchor-id="disadvantages-1">Disadvantages:</h5>
<p>Computationally expensive for large datasets. Choosing the right kernel and hyperparameters (e.g., <span class="math inline">\(C\)</span>, <span class="math inline">\(\gamma\)</span>) requires careful tuning.</p>
</section>
<section id="application-in-project-1" class="level4">
<h4 class="anchored" data-anchor-id="application-in-project-1">Application in Project:</h4>
<p>I will use SVM with various kernels, such as linear and radial basis function (RBF), to find the best fit for the dataset. Hyperparameter optimization (e.g., tuning for <span class="math inline">\(C\)</span> and <span class="math inline">\(\gamma\)</span>) will be performed to improve performance. Cross-validation will be used to ensure generalizability.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="data-analysis" class="level1">
<h1>Data Analysis</h1>
<section id="feature-selection-and-data-preprocessing-with-frequency-encoding" class="level2">
<h2 class="anchored" data-anchor-id="feature-selection-and-data-preprocessing-with-frequency-encoding">Feature Selection and Data Preprocessing with Frequency Encoding</h2>
<p>The dataset is from UC Irvine Machine Learning Repository with 17 variables and reduced from 45211 to 7842 observations by omitting entries with missing values. The dataset used for this analysis includes demographic, financial, and marketing-related features, all of which were carefully considered during feature selection. Binary variables such as housing, loan, default, and y were retained as they represent important binary decisions, particularly relevant in the context of financial services. These variables were converted to numeric values, where “yes” was encoded as 1 and “no” as 0. This transformation ensures compatibility with machine learning models while preserving the original meaning of these variables.</p>
<p>Categorical variables like job, education, marital, and contact were frequency encoded. Frequency encoding replaces each category with its proportion in the dataset, thereby retaining the relationship between the dataset distribution and the importance of the category without increasing dimensionality. Unlike one-hot encoding, which generates additional columns, frequency encoding keeps the feature space manageable and avoids potential overfitting caused by high-dimensional data.</p>
<p>Continuous variables such as age, balance, duration, and campaign were standardized to ensure all features contribute equally to machine learning models that are sensitive to the magnitude of input features, such as Support Vector Machines (SVM) or K-Nearest Neighbors (KNN). Standardization transforms each feature to have a mean of 0 and a standard deviation of 1, enabling better numerical stability and ensuring fair weight distribution across variables during model training.</p>
<p>The resulting dataset includes binary variables encoded as numeric values (0/1), frequency-encoded categorical variables, and scaled continuous variables. All missing values, originally represented as “unknown,” were either removed or imputed, depending on the extent of missingness. No features were excluded in this step, as all variables were deemed potentially valuable for predicting whether a client will subscribe to a term deposit. The correlation matrix below also helps verify the lack of multicollinearity or redundant features.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>In summary, the final preprocessed dataset is clean, fully numeric, and standardized, with all features prepared for effective use in model training and evaluation. This approach ensures that the dataset retains its predictive potential while addressing the challenges of high dimensionality and feature scale inconsistency.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>I proceed to train our model on the 80% training data, and then record its prediction error on left out 20% testing data for both KNN and SVM (Linear and RBF). The KNN model was tuned with the optimal K value and the SVM models were tuned with the optimal cost and/or gamma values. The following are the evaluation metrics for each model.</p>
<section id="confusion-matrix-for-evaluation-set" class="level5">
<h5 class="anchored" data-anchor-id="confusion-matrix-for-evaluation-set">Confusion Matrix for Evaluation Set</h5>
<p><span class="math inline">\(\textbf{Confusion Matrix: KNN}\)</span> <span class="math display">\[
\begin{array}{c|c|c}
           &amp; \textbf{Predicted No} &amp; \textbf{Predicted Yes} \\ \hline
\textbf{Actual No} &amp; 1116                 &amp; 189                  \\
\textbf{Actual Yes} &amp; 95                  &amp; 168                 \\
\end{array}
\]</span> <span class="math inline">\(\textbf{Confusion Matrix: SVM (RBF)}\)</span> <span class="math display">\[
\begin{array}{c|c|c}
           &amp; \textbf{Predicted No} &amp; \textbf{Predicted Yes} \\ \hline
\textbf{Actual No} &amp; 1122                 &amp; 173                  \\
\textbf{Actual Yes} &amp; 89                  &amp; 184                 \\
\end{array}
\]</span> <span class="math inline">\(\textbf{Confusion Matrix: SVM (Linear)}\)</span> <span class="math display">\[
\begin{array}{c|c|c}
           &amp; \textbf{Predicted No} &amp; \textbf{Predicted Yes} \\ \hline
\textbf{Actual No} &amp; 1121                 &amp; 179                  \\
\textbf{Actual Yes} &amp; 90                  &amp; 178                 \\
\end{array}
\]</span></p>
<div class="cell">
<div class="cell-output-display">

</div>
</div>
</section>
<section id="confusion-matrix-for-full-data-set" class="level5">
<h5 class="anchored" data-anchor-id="confusion-matrix-for-full-data-set">Confusion Matrix for Full Data Set</h5>
<p>I chose to keep use the SVM model with the radial basis function kernel since its Precision and Accuracy was noticeable better than the linear kernel’s metrics. The KNN and SVM (RBF) models was applied onto the full data set to checks its performance as seen below.</p>
<p><span class="math inline">\(\textbf{Confusion Matrix: KNN}\)</span> <span class="math display">\[
\begin{array}{c|c|c}
           &amp; \textbf{Predicted No} &amp; \textbf{Predicted Yes} \\ \hline
\textbf{Actual No} &amp; 5663 &amp; 872 \\
\textbf{Actual Yes} &amp; 393  &amp; 914 \\
\end{array}
\]</span> <span class="math inline">\(\textbf{Confusion Matrix: SVM (RBF)}\)</span> <span class="math display">\[
\begin{array}{c|c|c}
           &amp; \textbf{Predicted No} &amp; \textbf{Predicted Yes} \\ \hline
\textbf{Actual No} &amp; 5773 &amp; 677 \\
\textbf{Actual Yes} &amp; 283  &amp; 1109 \\
\end{array}
\]</span> <span class="math inline">\(\textbf{Model Performance Metrics on Full Data Set}\)</span></p>
<div class="cell">
<div class="cell-output-display">
<table class="table caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Performance Metrics: KNN vs SVM (RBF)</caption>
<thead>
<tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Metric</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">KNN</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">SVM..RBF.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">0.8387</td>
<td style="text-align: center;">0.8776</td>
</tr>
<tr class="even">
<td style="text-align: center;">Precision</td>
<td style="text-align: center;">0.8666</td>
<td style="text-align: center;">0.8950</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Recall</td>
<td style="text-align: center;">0.9351</td>
<td style="text-align: center;">0.9533</td>
</tr>
<tr class="even">
<td style="text-align: center;">F1-Score</td>
<td style="text-align: center;">0.8995</td>
<td style="text-align: center;">0.9232</td>
</tr>
</tbody>
</table>


</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This is a sample SVM plot of two features with the fitted boundary.</p>
</section>
</section>
<section id="model-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="model-evaluation">Model Evaluation</h2>
<p>The two models, KNN and SVM (using the RBF kernel), were trained and evaluated on the full dataset. Both models demonstrated strong performance, with slight variations in their respective metrics. The KNN model achieved an accuracy of 0.8387 and a precision of 0.8666, highlighting its effectiveness in minimizing false positives. This is particularly valuable for marketing campaigns where resources are limited, ensuring that clients predicted to subscribe are more likely to actually do so, thereby reducing wasted efforts on uninterested clients.</p>
<p>However, KNN’s recall (0.9351) was slightly lower compared to SVM, indicating that KNN might miss some potential subscribers. While this could result in missed revenue opportunities, the model’s higher precision makes it suitable for scenarios where avoiding false positives is critical. Additionally, KNN’s simplicity and ease of interpretation further solidify its role in contexts where explainability is essential.</p>
<p>The SVM model using the RBF kernel outperformed KNN in recall, achieving a rate of 0.9533, the highest among both models. This indicates SVM’s strength in identifying potential clients who are likely to subscribe, reducing false negatives. In marketing applications, this high recall ensures a wider reach and minimizes the risk of overlooking potential customers, although it comes at the cost of slightly lower precision (0.8950). This trade-off may result in contacting a few uninterested clients, which is acceptable in scenarios where maximizing client engagement is a priority.</p>
<p>The decision boundary visualization for SVM highlights its ability to model non-linear relationships within the data. This adaptability enables it to capture complex patterns in client behavior that simpler models, like KNN, may fail to recognize.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This study aimed to evaluate the effectiveness of two machine learning models—KNN and SVM with an RBF kernel—for predicting whether a client would subscribe to a term deposit. The analysis showed that while both models performed well, the SVM model with the RBF kernel outperformed the KNN model across all key performance metrics.</p>
<p>The SVM model achieved an accuracy of 87.76%, precision of 89.50%, recall of 95.33%, and an F1-score of 92.32%, outperforming KNN on every metric. Its superior recall highlights its ability to identify potential subscribers more effectively, reducing the number of false negatives. Additionally, its high precision ensures that the predicted subscribers are more likely to actually subscribe, which minimizes wasted marketing efforts. The SVM’s adaptability to capture non-linear relationships in the data likely contributed to its superior performance, making it a strong choice for this task.</p>
<p>In comparison, the KNN model achieved an accuracy of 83.87%, precision of 86.66%, recall of 93.51%, and an F1-score of 89.95%. While the KNN model showed reasonable performance, it lagged behind SVM on all fronts. Its slightly lower recall and precision indicate that it may miss some potential subscribers while also predicting a higher number of false positives compared to SVM. However, it is important to note that KNN remains a simpler and more interpretable model, which could still be valuable in situations where model explainability is critical.</p>
<section id="challenges-and-limitations" class="level2">
<h2 class="anchored" data-anchor-id="challenges-and-limitations">Challenges and Limitations</h2>
<p>During the analysis, several challenges were encountered:</p>
<ul>
<li>Imbalanced Data: The dataset was imbalanced, with a significantly higher proportion of clients not subscribing. While stratified train-test splits helped mitigate this, imbalanced data inherently impacts model performance and could bias predictions toward the majority class.</li>
<li>SVM Complexity: SVM required careful tuning of hyperparameters (e.g., cost and gamma) and was computationally intensive, especially when training on the full dataset. However, these efforts were justified by its superior performance.</li>
</ul>
</section>
<section id="future-improvements" class="level2">
<h2 class="anchored" data-anchor-id="future-improvements">Future Improvements</h2>
<p>To further enhance model performance and scalability, the following improvements are recommended:</p>
<ul>
<li>Feature Engineering: Additional feature engineering or feature selection techniques, such as principal component analysis (PCA) or recursive feature elimination, could reduce dimensionality and improve efficiency.</li>
<li>Addressing Class Imbalance: Techniques like SMOTE or class-weighted loss functions could help address class imbalance and improve the models’ ability to handle minority class predictions.</li>
<li>Exploration of Advanced Models: Incorporating ensemble methods, such as Random Forests or Gradient Boosting Machines, might yield even better predictive performance.</li>
<li>Model Deployment Considerations: Given SVM’s computational complexity, it may be worthwhile to explore approximate SVM implementations or alternatives like logistic regression for real-time deployment.</li>
</ul>
</section>
<section id="final-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="final-conclusion">Final Conclusion</h2>
<p>Based on the results, the SVM model with the RBF kernel is the clear winner for this application, delivering superior performance across accuracy, precision, recall, and F1-score. Its ability to balance identifying potential subscribers while maintaining high precision makes it the most reliable option for this marketing task. While KNN offers simplicity and interpretability, its lower performance metrics indicate that it is less suitable for this particular problem. In conclusion, SVM should be prioritized for deployment, especially in contexts where both recall and precision are critical to achieving marketing success.</p>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>Moro, S., Rita, P., &amp; Cortez, P. (2014). Bank Marketing [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5K306.</p>
<p>McKinsey &amp; Company. (2022). The state of customer care in 2022. Retrieved from https://shorturl.at/LsiQ7</p>
<p>Deloitte. (2022). Why all organizations need a Customer Service Strategy, now!. Retrieved from https://shorturl.at/aQdB3</p>
<p>James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2021). An introduction to statistical learning: With applications in R (2nd ed.). https://doi.org/10.1007/978-1-0716-1418-1</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>